{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e11e026-ebba-49f1-b61b-5a8c872154a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a469cd13-e8e9-4304-9b08-994ff55bab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7023 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#  load a dataset of images from a directory structure\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'DL_Brain_tumor',\n",
    "    shuffle = True,\n",
    "    image_size = (256,256),\n",
    "    batch_size = 32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce42047-7a45-414c-a204-f3bf56738fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "def split_dataset(dataset, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    val_size = int(val_ratio * dataset_size)\n",
    "\n",
    "    train_ds = dataset.take(train_size)\n",
    "    remaining = dataset.skip(train_size)\n",
    "    val_ds = remaining.take(val_size)\n",
    "    test_ds = remaining.skip(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "train_ds, val_ds, test_ds = split_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0f630d-9de3-4eb3-bb6c-0b7178bb5273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation completed!\n"
     ]
    }
   ],
   "source": [
    "# Data normalization\n",
    "normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "print(\"Data preparation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e3d476-2989-4b9e-be37-51a7cefed215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Data Augmentation (applies only to the training dataset)\n",
    "data_augmentation = Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Add data augmentation to training dataset\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# Prefetch data for better performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c0f6da-9732-437d-a557-837ab834133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 829ms/step - accuracy: 0.7573 - loss: 1.0243 - val_accuracy: 0.8331 - val_loss: 0.4535\n",
      "Epoch 2/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 916ms/step - accuracy: 0.8008 - loss: 0.5101 - val_accuracy: 0.8310 - val_loss: 0.4634\n",
      "Epoch 3/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 924ms/step - accuracy: 0.8044 - loss: 0.5045 - val_accuracy: 0.8274 - val_loss: 0.4593\n",
      "Epoch 4/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1328s\u001b[0m 9s/step - accuracy: 0.8018 - loss: 0.5061 - val_accuracy: 0.8324 - val_loss: 0.4500\n",
      "Epoch 5/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 851ms/step - accuracy: 0.8014 - loss: 0.5063 - val_accuracy: 0.8253 - val_loss: 0.4611\n",
      "Epoch 6/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 935ms/step - accuracy: 0.8035 - loss: 0.4998 - val_accuracy: 0.8274 - val_loss: 0.4567\n",
      "Epoch 7/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 964ms/step - accuracy: 0.8012 - loss: 0.5027 - val_accuracy: 0.8267 - val_loss: 0.4570\n",
      "Epoch 8/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 964ms/step - accuracy: 0.8038 - loss: 0.4983 - val_accuracy: 0.8267 - val_loss: 0.4592\n",
      "Epoch 9/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1653s\u001b[0m 11s/step - accuracy: 0.7990 - loss: 0.5097 - val_accuracy: 0.8310 - val_loss: 0.4504\n",
      "Epoch 10/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1000s\u001b[0m 7s/step - accuracy: 0.8016 - loss: 0.5014 - val_accuracy: 0.8317 - val_loss: 0.4517\n",
      "Epoch 11/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 835ms/step - accuracy: 0.8049 - loss: 0.4963 - val_accuracy: 0.8338 - val_loss: 0.4468\n",
      "Epoch 12/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 891ms/step - accuracy: 0.8038 - loss: 0.4986 - val_accuracy: 0.8274 - val_loss: 0.4576\n",
      "Epoch 13/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 915ms/step - accuracy: 0.8012 - loss: 0.4998 - val_accuracy: 0.8274 - val_loss: 0.4619\n",
      "Epoch 14/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 962ms/step - accuracy: 0.8044 - loss: 0.5013 - val_accuracy: 0.8246 - val_loss: 0.4652\n",
      "Epoch 15/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 979ms/step - accuracy: 0.8042 - loss: 0.4969 - val_accuracy: 0.8281 - val_loss: 0.4560\n",
      "Epoch 16/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.8024 - loss: 0.5008 - val_accuracy: 0.8317 - val_loss: 0.4570\n",
      "Epoch 17/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8026 - loss: 0.4944 - val_accuracy: 0.8295 - val_loss: 0.4529\n",
      "Epoch 18/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 1s/step - accuracy: 0.7999 - loss: 0.5012 - val_accuracy: 0.8295 - val_loss: 0.4556\n",
      "Epoch 19/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 1s/step - accuracy: 0.8009 - loss: 0.5028 - val_accuracy: 0.8338 - val_loss: 0.4521\n",
      "Epoch 20/20\n",
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.8003 - loss: 0.5033 - val_accuracy: 0.8331 - val_loss: 0.4484\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# Model Architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(dataset.class_names), activation='softmax')  # Adjust output layer to match the number of classes\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Change to 'categorical_crossentropy' if using one-hot encoding\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0aa2b59-683a-416d-a257-694d1b5dc9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.8112 - loss: 0.4854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4897303283214569, 0.807860255241394]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0f1195-d43a-4df6-9a07-cd9357727e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_tumor_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60086e27-a683-42fd-b8cd-07cc6ea73976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
